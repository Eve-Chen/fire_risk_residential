{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136   7]\n",
      " [ 92 108]]\n",
      "Accuracy = 0.7113702623906706 \n",
      " \n",
      "\n",
      "kappa score = 0.45270368281086304 \n",
      " \n",
      "\n",
      "AUC Score = 0.7455244755244755 \n",
      " \n",
      "\n",
      "recall = 0.54 \n",
      " \n",
      "\n",
      "precision = 0.9391304347826087 \n",
      " \n",
      "\n",
      "Start Feature Selection\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # importing relevant libraries\n",
    "# import matplotlib\n",
    "# # Force matplotlib to not use any Xwindows backend.\n",
    "# # matplotlib.use('Agg')\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import sqlalchemy as sa\n",
    "# import matplotlib.pyplot as plt\n",
    "# # from sklearn.decomposition import PCA\n",
    "# # from sklearn.preprocessing import scale\n",
    "# import pandas as pd\n",
    "# from sklearn import datasets, linear_model, cross_validation, grid_search\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.cross_validation import KFold, StratifiedKFold, cross_val_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn_pandas import DataFrameMapper\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# import datetime\n",
    "# from datetime import date\n",
    "# from dateutil.relativedelta import relativedelta\n",
    "# import os\n",
    "# import functools\n",
    "\n",
    "\n",
    "# # Turn off pandas chained assignment warning\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.display.max_columns = 999\n",
    "\n",
    "\n",
    "# # ### 1. CLEAN PLI, PITT & TAX DATA\n",
    "\n",
    "# # # create directory paths for opening files\n",
    "# # curr_path = ''\n",
    "# curr_path = os.path.dirname(os.path.realpath(\"fs_grid.ipynb\"))\n",
    "# dataset_path = os.path.join(curr_path, \"datasets/\")\n",
    "# inter_path = os.path.join(curr_path,\"interResults/\")\n",
    "\n",
    "# # read in data\n",
    "# # Reading plidata\n",
    "# plidata = pd.read_csv(os.path.join(dataset_path, \"pli.csv\"), encoding='utf-8', dtype={'STREET_NUM': 'str', 'STREET_NAME': 'str'}, low_memory=False)\n",
    "# # Reading city of Pittsburgh dataset\n",
    "# pittdata = pd.read_csv(os.path.join(dataset_path, \"pittdata.csv\"), encoding=\"ISO-8859-1\", dtype={'PROPERTYADDRESS': 'str', 'PROPERTYHOUSENUM': 'str', 'CLASSDESC': 'str'}, low_memory=False)\n",
    "# # Reading tax data\n",
    "# taxdata = pd.read_csv(\"./datasets/tax.csv\", encoding='utf-8')\n",
    "# #read parcel data (matches parcels to census tract and block group\n",
    "# parcel = pd.read_csv(os.path.join(dataset_path, \"parcels.csv\"), encoding='utf-8')\n",
    "# #read ACS data\n",
    "# acs_data = ['acs_income.csv','acs_occupancy.csv','acs_year_built.csv','acs_year_moved.csv']\n",
    "# def clean_acs(df):\n",
    "#     #Use descriptive names in first row\n",
    "#     df.columns = df.loc[0]\n",
    "#     df = df.drop(0)\n",
    "#     df = df.drop(['Id', 'Id2'], axis=1)\n",
    "#     #Extract census block and tract\n",
    "#     df[['BLOCKCE10', 'TRACTCE10']] = df['Geography'].str.extract(\n",
    "#         'Block Group (\\d), Census Tract (\\d+\\.?\\d*)')\n",
    "#     df = df.drop(['Geography'], axis=1)\n",
    "#     #Drop first two columns since they only contain totals\n",
    "#     df = df.drop(df.columns[[0,1]], axis=1)\n",
    "#     #Drop margin of errors\n",
    "#     df = df.drop(df.columns[df.columns.str.startswith('Margin')], axis=1)\n",
    "#     #Convert to numbers\n",
    "#     df['BLOCKCE10'] = df['BLOCKCE10'].astype('float')\n",
    "#     df['TRACTCE10'] = df['TRACTCE10'].astype('float')\n",
    "#     #Multiply tract by 100 to be consistent with other data\n",
    "#     df['TRACTCE10'] = df['TRACTCE10'] * 100\n",
    "#     return df\n",
    "# acs_data = map(lambda x: os.path.join(dataset_path, x), acs_data)\n",
    "# acs_data = map(pd.read_csv, acs_data)\n",
    "# acs_data = map(clean_acs, acs_data)\n",
    "# #Merge datasets together\n",
    "# acs_data_combined = functools.reduce(lambda x,y:x.merge(y, how='outer', on=['BLOCKCE10','TRACTCE10']), acs_data)\n",
    "\n",
    "# # cleaning pitt dataset\n",
    "# # removing all properties outside Pittsburgh, Wilkinsburg, and Ingram\n",
    "# pittdata = pittdata[(pittdata.PROPERTYCITY == 'PITTSBURGH')]  # & (pittdata.PROPERTYCITY == 'WILKINSBURG') & (pittdata.PROPERTYCITY == 'INGRAM')]\n",
    "# # include only residential data\n",
    "# pittdata = pittdata[pittdata['CLASSDESC'] == 'RESIDENTIAL']\n",
    "# address_parcels = pittdata[['PARID','PROPERTYADDRESS','PROPERTYHOUSENUM']].drop_duplicates()\n",
    "# pittdata = pittdata[pittdata['PROPERTYHOUSENUM'] != '0']\n",
    "# pittdata = pittdata[pittdata['PROPERTYADDRESS'] != '']\n",
    "# # dropping columns with less than 15% data\n",
    "# pittdata = pittdata.dropna(thresh=4000, axis=1)\n",
    "# pittdata = pittdata.rename(columns={pittdata.columns[0]: 'PARID'})\n",
    "# # pick out necessary columns\n",
    "# pittdata = pittdata[['PARID','PROPERTYHOUSENUM','PROPERTYADDRESS','MUNIDESC','SCHOOLDESC','NEIGHCODE',\n",
    "#                      'TAXDESC','OWNERDESC','USEDESC','LOTAREA','SALEPRICE','FAIRMARKETBUILDING','FAIRMARKETLAND']]\n",
    "# pittdata = pittdata.drop_duplicates()\n",
    "\n",
    "# # cleaning pli dataset\n",
    "# # removing extra whitespaces\n",
    "# plidata['STREET_NAME'] = plidata['STREET_NAME'].str.strip()\n",
    "# plidata['STREET_NUM'] = plidata['STREET_NUM'].str.strip()\n",
    "# # include only residential data\n",
    "# plidata = pd.merge(plidata, address_parcels[['PARID']], how='inner',left_on=['PARCEL'], right_on=['PARID'])\n",
    "# # pick out necessary columns\n",
    "# plidata=plidata[['PARCEL', 'INSPECTION_DATE', 'INSPECTION_RESULT', 'VIOLATION']]\n",
    "# # converting to datetime\n",
    "# plidata.INSPECTION_DATE = pd.to_datetime(plidata.INSPECTION_DATE)\n",
    "# plidata['violation_year'] = plidata['INSPECTION_DATE'].map(lambda x: x.year)\n",
    "# plidata = plidata.drop_duplicates()\n",
    "\n",
    "# # cleaning tax dataset\n",
    "# # removing all properties outside Pittsburgh, Wilkinsburg, and Ingram\n",
    "# taxdata = taxdata[(taxdata.municipality == 'Pittsburgh')]  # & (tax.municipality == 'Wilkinsburg Boro') & (tax.municipality == 'Ingram Boro')]\n",
    "# taxdata = taxdata.dropna(subset=['pin', 'tax_year', 'lien_description', 'amount', 'satisfied'])\n",
    "# # include only residential data\n",
    "# taxdata = pd.merge(taxdata, address_parcels[['PARID']], how='inner', left_on=['pin'], right_on=['PARID'])\n",
    "# # pick out necessary columns\n",
    "# taxdata = taxdata[['pin', 'filing_date', 'tax_year', 'lien_description', 'amount','satisfied']]\n",
    "# taxdata.filing_date = pd.to_datetime(taxdata.filing_date)\n",
    "# taxdata.tax_year=taxdata['tax_year'].apply(lambda x: date(x,12,31))\n",
    "# taxdata.tax_year = pd.to_datetime(taxdata.tax_year)\n",
    "# taxdata = taxdata.drop_duplicates()\n",
    "\n",
    "# # cleaning parcel dataset\n",
    "# # keep only parcel, tract, and block group\n",
    "# parcel = parcel[(parcel.geo_name_cousub == 'Pittsburgh city')]\n",
    "# parcel_blocks = parcel[['PIN', 'TRACTCE10', 'BLOCKCE10']]\n",
    "# #get first digit of block, convert to int\n",
    "# parcel_blocks['BLOCKCE10'] = parcel_blocks['BLOCKCE10'].astype(str).str[0].astype(float)\n",
    "# #ignore bad parcels\n",
    "# parcel_blocks = parcel_blocks[parcel_blocks['PIN'] != ' ']\n",
    "# parcel_blocks = parcel_blocks[parcel_blocks['PIN'] != 'COMMON GROUND']\n",
    "# parcel_blocks = parcel_blocks[~parcel_blocks['PIN'].str.match('.*County')]\n",
    "# parcel_blocks=parcel_blocks.drop_duplicates()\n",
    "\n",
    "\n",
    "# # #### 1.1 Aggregate pittdata to census block, then merge with acs data\n",
    "\n",
    "\n",
    "\n",
    "# pittdata_blocks=pd.merge(pittdata, parcel_blocks, how='left', left_on=['PARID'], right_on=['PIN'])\n",
    "# #drop extra columns\n",
    "# pittdata_blocks = pittdata_blocks.drop(['PARID','PIN','PROPERTYHOUSENUM','PROPERTYADDRESS'], axis=1)\n",
    "\n",
    "\n",
    "# #group by blocks\n",
    "# grouped = pittdata_blocks.groupby(['TRACTCE10','BLOCKCE10'])\n",
    "# #change the '-DESC' columns to the most common in each group (block)\n",
    "# #change the other columns to the mean\n",
    "# max_count = lambda x:x.value_counts().index[0]\n",
    "# pittdata_blocks = grouped.agg({\n",
    "#     'MUNIDESC':max_count,'SCHOOLDESC':max_count,'NEIGHCODE':max_count,\n",
    "#     'TAXDESC':max_count,'OWNERDESC':max_count,'USEDESC':max_count,'LOTAREA':np.mean,\n",
    "#     'SALEPRICE':np.mean,'FAIRMARKETBUILDING':np.mean,'FAIRMARKETLAND':np.mean\n",
    "# })\n",
    "# #reset index to columns\n",
    "# pittdata_blocks = pittdata_blocks.reset_index(level=[0,1])\n",
    "# #merge pittdata with acs\n",
    "# pittacs = pd.merge(pittdata_blocks, acs_data_combined, how='inner', on=['BLOCKCE10','TRACTCE10'])\n",
    "\n",
    "# # keep a copy of blocks and tracts\n",
    "# blocks = pittacs[['TRACTCE10','BLOCKCE10']].drop_duplicates()\n",
    "\n",
    "\n",
    "# # #### 1.2 merge plidata with census block¶\n",
    "\n",
    "# #group by blocks\n",
    "# plidata_blocks = pd.merge(plidata, parcel_blocks, how='left', left_on=['PARCEL'], right_on=['PIN'])\n",
    "# #drop extra columns\n",
    "# plidata_blocks = plidata_blocks.drop(['PARCEL','PIN'], axis=1)\n",
    "# plidata_blocks=plidata_blocks.dropna(subset=['TRACTCE10','BLOCKCE10'])\n",
    "\n",
    "\n",
    "# # #### 1.3 Aggregate taxdata to census block¶\n",
    "\n",
    "# # group by blocks\n",
    "# taxdata_blocks = pd.merge(taxdata,parcel_blocks, how='left', left_on=['pin'], right_on=['PIN'])\n",
    "# taxdata_blocks = taxdata_blocks.drop(['pin','PIN'],axis=1)\n",
    "# taxdata_blocks = taxdata_blocks.dropna(subset=['TRACTCE10','BLOCKCE10'])\n",
    "\n",
    "\n",
    "# # ### 2. Clean fire incident data\n",
    "\n",
    "# # loading fire incidents csvs\n",
    "# fire_pre14 = pd.read_csv(os.path.join(dataset_path, \"Fire_Incidents_Pre14.csv\"), encoding='latin-1', dtype={'street': 'str', 'number': 'str'}, low_memory=False)\n",
    "# fire_new = pd.read_csv(os.path.join(dataset_path, \"Fire_Incidents_New.csv\"), encoding='utf-8', dtype={'street': 'str', 'number': 'str'}, low_memory=False)\n",
    "\n",
    "# # cleaning columns of fire_pre14\n",
    "# fire_pre14['full.code'] = fire_pre14['full.code'].str.replace('  -', ' -')\n",
    "# fire_pre14['st_type'] = fire_pre14['st_type'].str.strip()\n",
    "# fire_pre14['street'] = fire_pre14['street'].str.strip()\n",
    "# fire_pre14['number'] = fire_pre14['number'].str.strip()\n",
    "# fire_pre14['st_type'] = fire_pre14['st_type'].str.replace('AV', 'AVE')\n",
    "# fire_pre14['street'] = fire_pre14['street'].str.strip() + ' ' + fire_pre14['st_type'].str.strip()\n",
    "\n",
    "# # drop irrelevant columns\n",
    "# pre14_drop = ['Unnamed: 0','PRIMARY_UNIT', 'MAP_PAGE', 'alm_dttm', 'arv_dttm', 'XCOORD', \n",
    "#               'YCOORD','inci_id', 'inci_type', 'alarms', 'st_prefix',\n",
    "#               'st_suffix', 'st_type', 'CALL_NO','descript']\n",
    "# for col in pre14_drop:\n",
    "#   del fire_pre14[col]\n",
    "\n",
    "\n",
    "# post14_drop = ['alm_dttm', 'arv_dttm', 'XCOORD', 'YCOORD', 'alarms', \n",
    "#                'inci_type', 'CALL_NO','descript']\n",
    "# for col in post14_drop:\n",
    "#   del fire_new[col]\n",
    "\n",
    "# # joining both the fire incidents file together\n",
    "# fire_new = fire_new.append(fire_pre14, ignore_index=True)\n",
    "# fire_new = fire_new[fire_new['full.code'].str.strip() != '540 - Animal problem, Other']\n",
    "# fire_new = fire_new[fire_new['full.code'].str.strip() != '5532 - Public Education (Station Visit)']\n",
    "# fire_new = fire_new[fire_new['full.code'].str.strip() != '353 - Removal of victim(s) from stalled elevator']\n",
    "\n",
    "# # correcting problems with the street column\n",
    "# fire_new['street'] = fire_new['street'].replace(to_replace=', PGH', value='', regex=True)\n",
    "# fire_new['street'] = fire_new['street'].replace(to_replace=', P', value='', regex=True)\n",
    "# fire_new['street'] = fire_new['street'].replace(to_replace=',', value='', regex=True)\n",
    "# fire_new['street'] = fire_new['street'].replace(to_replace='#.*', value='', regex=True)\n",
    "# fire_new['street'] = fire_new['street'].str.strip()\n",
    "# fire_new['number'] = fire_new['number'].str.strip()\n",
    "\n",
    "# # converting to date time and extracting year\n",
    "# fireDate, fireTime = fire_new['CALL_CREATED_DATE'].str.split(' ', 1).str\n",
    "# fire_new['CALL_CREATED_DATE'] = fireDate\n",
    "# fire_new['CALL_CREATED_DATE'] = pd.to_datetime(fire_new['CALL_CREATED_DATE'])\n",
    "# fire_new['fire_year'] = fire_new['CALL_CREATED_DATE'].map(lambda x: x.year)\n",
    "\n",
    "# # removing all codes with less than 20 occurences\n",
    "# for col, val in fire_new['full.code'].value_counts().iteritems():\n",
    "#     if val < 20 and col[0] != '1':\n",
    "#         fire_new = fire_new[fire_new['full.code'] != col]\n",
    "\n",
    "# #Split street column when there are 2 streets\n",
    "# street_split = fire_new['street'].str.split('/')\n",
    "# fire_new['street'] = street_split.map(lambda x:x[0])\n",
    "# fire_new = fire_new.dropna(subset=['CALL_CREATED_DATE'])\n",
    "# fire_new = fire_new.drop_duplicates()\n",
    "\n",
    "\n",
    "# # #### 2.1 merge fire incident to census block\n",
    "\n",
    "# # convert from addresses to parcels\n",
    "# fire_parcel = pd.merge(fire_new, address_parcels, how='inner',\n",
    "#                         left_on=['street','number'], right_on=['PROPERTYADDRESS','PROPERTYHOUSENUM'])\n",
    "# # convert from parcels to census blocks\n",
    "# fire_blocks = pd.merge(fire_parcel, parcel_blocks, how='left',left_on=['PARID'], right_on=['PIN'])\n",
    "# #drop extra columns\n",
    "# fire_blocks=fire_blocks.drop(['number','street','PARID','PROPERTYADDRESS',\n",
    "#                               'PROPERTYHOUSENUM','PIN', 'Unnamed: 0',\n",
    "#                               'st_prefix', 'st_suffix', 'st_type',\n",
    "#                               'prop_use_code','response_time',\n",
    "#                               'CALL_TYPE_FINAL', 'COUNCIL', 'NEIGHBORHOOD',\n",
    "#                               'PRIMARY_UNIT','fire_year','prop_use_descript'],axis=1)\n",
    "# #drop data without block or tract (this drops non-residential data)\n",
    "# fire_blocks = fire_blocks.dropna(subset=['TRACTCE10','BLOCKCE10'])\n",
    "# # dropping columns with less than 15% data\n",
    "# fire_blocks = fire_blocks.dropna(thresh=len(fire_blocks)*0.15, axis=1)\n",
    "# fire_blocks = fire_blocks.drop_duplicates()\n",
    "\n",
    "\n",
    "# # ### 3 Join four datasets together\n",
    "\n",
    "# # #### 3.1 joining dynamic data with fire incidents\n",
    "\n",
    "# # making the fire column with all type 100s as fires and map it to 0 or 1\n",
    "# fire_blocks['fire'] = fire_blocks['full.code'].astype(str).                    map(lambda x: 1 if x[0]=='1' else 0)\n",
    "# # keep non-fire incidents as features\n",
    "# nonfire_incidents = fire_blocks[fire_blocks['fire'] != 1]\n",
    "# nonfire_incidents = nonfire_incidents[['CALL_CREATED_DATE','full.code','TRACTCE10', 'BLOCKCE10']]\n",
    "# fire_blocks.drop('full.code',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# # group by every certain period of time\n",
    "# # reason for setting period to year: tax data is based on year\n",
    "# period = 'A'\n",
    "# fire_groups = fire_blocks.groupby(pd.Grouper(key='CALL_CREATED_DATE', freq=period))\n",
    "# nonfire_groups = nonfire_incidents.groupby(pd.Grouper(key='CALL_CREATED_DATE', freq=period))\n",
    "# plidata_groups = plidata_blocks.groupby(pd.Grouper(key='INSPECTION_DATE', freq=period))\n",
    "# taxdata_groups = taxdata_blocks.groupby(pd.Grouper(key='tax_year', freq=period))\n",
    "\n",
    "# get the date of the earliest fire in each block in each year\n",
    "block_fire_dates = fire_groups.apply(lambda x:x.groupby(['TRACTCE10','BLOCKCE10']).apply(lambda x:x[x['fire']==1].min()))\n",
    "\n",
    "# then group fire by census blocks\n",
    "def groupByBlock(df,categoricals, method):\n",
    "    dummies=[pd.get_dummies(df[feature]) for feature in categoricals]\n",
    "    df = pd.concat([df]+dummies,axis=1)\n",
    "    df.drop(categoricals,axis=1,inplace=True)\n",
    "    df = pd.merge(df, blocks, how='right',on=['TRACTCE10','BLOCKCE10'])\n",
    "    df_grouped=df.groupby(['TRACTCE10','BLOCKCE10'])\n",
    "    if method == 'max':\n",
    "        df_grouped=df_grouped.max()\n",
    "    if method == 'sum':\n",
    "        df_grouped=df_grouped.sum()\n",
    "    return df_grouped\n",
    "fire_divided = fire_groups.apply(groupByBlock,categoricals=[],method='max')\n",
    "fire_divided.drop('CALL_CREATED_DATE',axis=1,inplace=True)\n",
    "fire_divided=fire_divided.reset_index()\n",
    "fire_divided=fire_divided.fillna(0)\n",
    "\n",
    "\n",
    "# group nonfire incidents by census blocks\n",
    "def groupByBlockNonfire(df, categoricals, method):\n",
    "    # only keep data that occurred before the fire\n",
    "    year = df['CALL_CREATED_DATE'].iloc[0].year\n",
    "    df = pd.merge(df, block_fire_dates[block_fire_dates['CALL_CREATED_DATE'].dt.year == year], how='left',\n",
    "                  on=['TRACTCE10', 'BLOCKCE10'], suffixes=['', '_F'])\n",
    "    df['CALL_CREATED_DATE_F'] = df['CALL_CREATED_DATE_F'].fillna(pd.to_datetime('12-31-' + str(year)))\n",
    "    df = df[df['CALL_CREATED_DATE'] <= df['CALL_CREATED_DATE_F']]\n",
    "    df = df.drop(['CALL_CREATED_DATE_F', 'fire'], axis=1)\n",
    "\n",
    "    dummies = [pd.get_dummies(df[feature]) for feature in categoricals]\n",
    "    df = pd.concat([df] + dummies, axis=1)\n",
    "    df.drop(categoricals, axis=1, inplace=True)\n",
    "    df = pd.merge(df, blocks, how='right', on=['TRACTCE10', 'BLOCKCE10'])\n",
    "    df_grouped = df.groupby(['TRACTCE10', 'BLOCKCE10'])\n",
    "    if method == 'max':\n",
    "        df_grouped = df_grouped.max()\n",
    "    if method == 'sum':\n",
    "        df_grouped = df_grouped.sum()\n",
    "    return df_grouped\n",
    "\n",
    "nonfire_divided = nonfire_groups.apply(groupByBlockNonfire,categoricals=['full.code'],method='sum')\n",
    "nonfire_divided=nonfire_divided.reset_index()\n",
    "nonfire_divided=nonfire_divided.fillna(0)\n",
    "\n",
    "\n",
    "# group pli incidents by census blocks\n",
    "def groupByBlock_pli(df):\n",
    "    # only keep data that occurred before the fire\n",
    "    year = df['INSPECTION_DATE'].iloc[0].year\n",
    "    df = pd.merge(df, block_fire_dates[block_fire_dates['CALL_CREATED_DATE'].dt.year == year], how='left',\n",
    "                  on=['TRACTCE10', 'BLOCKCE10'])\n",
    "    df['CALL_CREATED_DATE'] = df['CALL_CREATED_DATE'].fillna(pd.to_datetime('12-31-' + str(year)))\n",
    "    df = df[df['INSPECTION_DATE'] <= df['CALL_CREATED_DATE']]\n",
    "    df = df.drop(['CALL_CREATED_DATE', 'fire'], axis=1)\n",
    "    \n",
    "    INSPECTION_RESULT_dummies=pd.get_dummies(df['INSPECTION_RESULT'])\n",
    "    VIOLATION_dummies=df['VIOLATION'].str.get_dummies(sep=' :: ')\n",
    "    df = pd.concat([df,INSPECTION_RESULT_dummies,VIOLATION_dummies],axis=1)\n",
    "    df.drop(['INSPECTION_RESULT','VIOLATION','violation_year'],axis=1,inplace=True)\n",
    "    df = pd.merge(df, blocks, how='right',on=['TRACTCE10','BLOCKCE10'])\n",
    "    df_grouped=df.groupby(['TRACTCE10','BLOCKCE10']).sum()\n",
    "    return df_grouped\n",
    "pli_divided=plidata_groups.apply(groupByBlock_pli)\n",
    "pli_divided=pli_divided.reset_index()\n",
    "pli_divided=pli_divided.fillna(0)\n",
    "\n",
    "\n",
    "# group tax data by census blocks\n",
    "def groupByBlock_tax(df):\n",
    "    tax_dummies=pd.get_dummies(df['lien_description'])\n",
    "    df = pd.concat([df,tax_dummies],axis=1)\n",
    "    df.drop(['lien_description'],axis=1,inplace=True)\n",
    "    df = pd.merge(df, blocks, how='right',on=['TRACTCE10','BLOCKCE10'])\n",
    "    df_grouped=df.groupby(['TRACTCE10','BLOCKCE10']).sum()\n",
    "    return df_grouped\n",
    "\n",
    "tax_divided=taxdata_groups.apply(groupByBlock,categoricals=['lien_description'],method='sum')\n",
    "tax_divided=tax_divided.reset_index()\n",
    "tax_divided=tax_divided.fillna(0)\n",
    "\n",
    "\n",
    "# join fire, nonfire, pli, tax data together\n",
    "fire_nonfire = pd.merge(fire_divided,nonfire_divided,how='outer',\n",
    "                        on=['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'])\n",
    "fire_nonfire_pli = pd.merge(fire_nonfire,pli_divided,how='outer',\n",
    "                           left_on=['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'],\n",
    "                           right_on=['INSPECTION_DATE','TRACTCE10','BLOCKCE10'])\n",
    "fire_nonfire_pli_tax = pd.merge(fire_nonfire_pli,tax_divided,how='outer',\n",
    "                               left_on=['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'],\n",
    "                               right_on=['tax_year','TRACTCE10','BLOCKCE10'])\n",
    "fire_nonfire_pli_tax['CALL_CREATED_DATE']=fire_nonfire_pli_tax['CALL_CREATED_DATE'].                                           fillna(fire_nonfire_pli_tax['CALL_CREATED_DATE'])\n",
    "fire_nonfire_pli_tax.drop(['INSPECTION_DATE','tax_year'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# drop columns with less than thresold% data\n",
    "threshold=0.0001\n",
    "s=fire_nonfire_pli_tax.sum()\n",
    "drop_columns=s[s<len(fire_nonfire_pli_tax)*threshold].index\n",
    "fire_nonfire_pli_tax.drop(drop_columns,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# join with pitt_blocks\n",
    "combined = pd.merge(fire_nonfire_pli_tax,pittacs,\n",
    "                    how='left',on=['TRACTCE10','BLOCKCE10'])\n",
    "features = ['SCHOOLDESC', 'OWNERDESC', 'MUNIDESC', 'NEIGHCODE','TAXDESC', 'USEDESC']\n",
    "dummies= [pd.get_dummies(combined[feature]) for feature in features]\n",
    "encoded_combined=pd.concat([combined]+dummies,axis=1)\n",
    "encoded_combined.drop(features,axis=1,inplace=True)\n",
    "encoded_combined=encoded_combined.dropna(subset=['CALL_CREATED_DATE'])\n",
    "encoded_combined = encoded_combined.drop_duplicates()\n",
    "encoded_combined=encoded_combined.fillna(0)\n",
    "encoded_combined = encoded_combined[encoded_combined.CALL_CREATED_DATE <= '2017-12-31']\n",
    "\n",
    "# ### 4 Split data into training set and test set\n",
    "# PREPARING THE TESTING DATA (final 1 year of data)\n",
    "cutoffdate = '2016-12-31'\n",
    "# preparing training set\n",
    "encoded_traindata = encoded_combined[encoded_combined.CALL_CREATED_DATE <= cutoffdate]\n",
    "\n",
    "#making valuation dataset before CALL_CREATED_DATE is deleted\n",
    "val_cutoffdate = '2015-12-31'\n",
    "\n",
    "encoded_traindata.to_csv(\"encode_train.csv\")\n",
    "valuation_data = encoded_traindata[encoded_traindata.CALL_CREATED_DATE > val_cutoffdate]\n",
    "fs_train_data = encoded_traindata[encoded_traindata.CALL_CREATED_DATE <= val_cutoffdate]\n",
    "\n",
    "valuation_data = valuation_data.drop(['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'], axis=1)\n",
    "fs_train_data = fs_train_data.drop(['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'], axis=1)\n",
    "\n",
    "encoded_traindata.drop(['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'],axis=1,inplace=True)\n",
    "encoded_traindata.fillna(0)\n",
    "X_train=np.array(encoded_traindata.drop(['fire'],axis=1))\n",
    "y_train=np.array(encoded_traindata['fire'])\n",
    "\n",
    "# preparing test set\n",
    "encoded_testdata = encoded_combined[encoded_combined.CALL_CREATED_DATE > cutoffdate]\n",
    "encoded_testdata.drop(['CALL_CREATED_DATE','TRACTCE10','BLOCKCE10'],axis=1,inplace=True)\n",
    "encoded_testdata.fillna(0)\n",
    "X_test=np.array(encoded_testdata.drop(['fire'],axis=1))\n",
    "y_test=np.array(encoded_testdata['fire'])\n",
    "\n",
    "#converting to array and reshaping the data to prep for model\n",
    "fireVarTrain = encoded_traindata['fire']\n",
    "#del encoded_traindata['fire']\n",
    "no_fire_train = encoded_traindata.drop(['fire'], axis =1)\n",
    "X_train = np.array(no_fire_train)\n",
    "y_train = np.reshape(fireVarTrain.values,[fireVarTrain.shape[0],])\n",
    "\n",
    "#converting to array and reshaping the data to prep for model\n",
    "fireVarTest = encoded_testdata['fire']\n",
    "#del encoded_testdata['fire']\n",
    "no_fire_test = encoded_testdata.drop(['fire'], axis =1)\n",
    "#dropping fire attribute to make fire valuation dataset later\n",
    "X_test = np.array(no_fire_test)\n",
    "y_test = np.reshape(fireVarTest.values,[fireVarTest.shape[0],])\n",
    "\n",
    "X_validation = np.array(fs_train_data.drop(['fire'], axis=1))\n",
    "y_validation = np.array(fs_train_data['fire'])\n",
    "\n",
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 65)\n",
    "model.fit(X_train, y_train)\n",
    "pred_rf = model.predict(X_test)\n",
    "real = y_test\n",
    "cm_rf = confusion_matrix(real, pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "kappa_rf = cohen_kappa_score(real, pred_rf)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_rf, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "acc_rf = 'Accuracy = {0} \\n \\n'.format(float(cm_rf[0][0] + cm_rf[1][1]) / len(real))\n",
    "kapp_rf = 'kappa score = {0} \\n \\n'.format(kappa_rf)\n",
    "auc_rf = 'AUC Score = {0} \\n \\n'.format(metrics.auc(fpr, tpr))\n",
    "recall_rf = 'recall = {0} \\n \\n'.format(tpr[1])\n",
    "precis_rf = 'precision = {0} \\n \\n'.format(float(cm_rf[1][1]) / (cm_rf[1][1] + cm_rf[0][1]))\n",
    "\n",
    "print(acc_rf)\n",
    "print(kapp_rf)\n",
    "print(auc_rf)\n",
    "print(recall_rf)\n",
    "print(precis_rf)\n",
    "\n",
    "print(\"Start Feature Selection\")\n",
    "# ==== Feature Selection using Feature Importance =====\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# calculate imputed test dataset\n",
    "imputed_fireVarTest = fireVarTest.fillna(method=\"ffill\")\n",
    "impute_X_test = np.array(encoded_testdata.drop('fire',axis=1).fillna(method=\"ffill\"))\n",
    "impute_y_test = np.reshape(imputed_fireVarTest.values, [imputed_fireVarTest.shape[0],])\n",
    "\n",
    "#model for feature selection\n",
    "selection_model = RandomForestClassifier(n_estimators = 60, max_depth=3, random_state=27)\n",
    "\n",
    "# create the list of features with corresponding feature importances\n",
    "feature_importance = pd.Series(data=model.feature_importances_, index=encoded_traindata.drop(['fire'], axis =1).columns)\n",
    "\n",
    "\n",
    "#sort the feature importance from low to hi\n",
    "feature_importance = feature_importance.sort_values()\n",
    "# Making threshold smaller\n",
    "thresh_num = X_validation.shape[1]\n",
    "\n",
    "feature_result = pd.DataFrame(columns=('Last_Feature', 'Thresh', 'Acc', 'Kapp', 'AUC', 'Recall', 'Precis'))\n",
    "low_thresh = feature_importance[0]\n",
    "print(feature_importance[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138   5]\n",
      " [101  99]]\n",
      "Accuracy = 0.6909620991253644 \n",
      " \n",
      "\n",
      "kappa score = 0.41986852182792955 \n",
      " \n",
      "\n",
      "AUC Score = 0.7300174825174826 \n",
      " \n",
      "\n",
      "recall = 0.495 \n",
      " \n",
      "\n",
      "precision = 0.9519230769230769 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adaboost model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model_adaboost = AdaBoostClassifier(n_estimators = 65, random_state=27)\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "#pred_adaboost = model_adaboost.predict(X_validation)\n",
    "pred_adaboost = model_adaboost.predict(X_test)\n",
    "#real_adaboost = y_validation\n",
    "real_adaboost = y_test\n",
    "cm_ada = confusion_matrix(real_adaboost, pred_adaboost)\n",
    "print(cm_ada)\n",
    "\n",
    "kappa_ada = cohen_kappa_score(real_adaboost, pred_adaboost)\n",
    "\n",
    "#compute ROC curve and area under the curve\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_validation, pred_adaboost, pos_label=1)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_adaboost, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "acc_ada = 'Accuracy = {0} \\n \\n'.format(float(cm_ada[0][0] + cm_ada[1][1]) / len(real_adaboost))\n",
    "kapp_ada = 'kappa score = {0} \\n \\n'.format(kappa_ada)\n",
    "auc_ada = 'AUC Score = {0} \\n \\n'.format(metrics.auc(fpr, tpr))\n",
    "recall_ada = 'recall = {0} \\n \\n'.format(tpr[1])\n",
    "precis_ada = 'precision = {0} \\n \\n'.format(float(cm_ada[1][1]) / (cm_ada[1][1] + cm_ada[0][1]))\n",
    "\n",
    "print(acc_ada)\n",
    "print(kapp_ada)\n",
    "print(auc_ada)\n",
    "print(recall_ada)\n",
    "print(precis_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141   2]\n",
      " [ 93 107]]\n",
      "Accuracy = 0.7230320699708455 \n",
      " \n",
      "\n",
      "kappa score = 0.477695673778191 \n",
      " \n",
      "\n",
      "AUC Score = 0.7605069930069931 \n",
      " \n",
      "\n",
      "recall = 0.535 \n",
      " \n",
      "\n",
      "precision = 0.981651376146789 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The XG Boost model\n",
    "model_xgboost = XGBClassifier(learning_rate=0.13, n_estimators=1500,\n",
    "                              objective='binary:logistic',nthread=4,seed=27)\n",
    "model_xgboost.fit(X_train, y_train)\n",
    "# pred_xgboost = model_xgboost.predict(X_validation)\n",
    "pred_xgboost = model_xgboost.predict(X_test)\n",
    "# real_xgboost = y_validation\n",
    "real_xgboost = y_test\n",
    "cm_xg = confusion_matrix(real_xgboost, pred_xgboost)\n",
    "print(cm_xg)\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa_xg = cohen_kappa_score(real_xgboost, pred_xgboost)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_xgboost, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "acc_xg = 'Accuracy = {0} \\n \\n'.format(float(cm_xg[0][0] + cm_xg[1][1]) / len(real_xgboost))\n",
    "kapp_xg = 'kappa score = {0} \\n \\n'.format(kappa_xg)\n",
    "auc_xg = 'AUC Score = {0} \\n \\n'.format(metrics.auc(fpr, tpr))\n",
    "recall_xg = 'recall = {0} \\n \\n'.format(tpr[1])\n",
    "precis_xg = 'precision = {0} \\n \\n'.format(float(cm_xg[1][1]) / (cm_xg[1][1] + cm_xg[0][1]))\n",
    "\n",
    "print(acc_xg)\n",
    "print(kapp_xg)\n",
    "print(auc_xg)\n",
    "print(recall_xg)\n",
    "print(precis_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "best row:\n",
      "Last_Feature    2003 IPMC 307.1 Accumulation of rubbish or gar...\n",
      "Thresh                                                  0.0023494\n",
      "Acc                                                      0.898931\n",
      "Kapp                                                     0.797433\n",
      "AUC                                                      0.899723\n",
      "Recall                                                    0.88808\n",
      "Precis                                                   0.919887\n",
      "F1                                                       0.903704\n",
      "Name: 363, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#model for feature selection\n",
    "selection_model = RandomForestClassifier(n_estimators = 60, max_depth=3, random_state=27)\n",
    "\n",
    "# create the list of features with corresponding feature importances\n",
    "feature_importance = pd.Series(data=model.feature_importances_, index=encoded_traindata.drop(['fire'], axis =1).columns)\n",
    "\n",
    "\n",
    "#sort the feature importance from low to hi\n",
    "feature_importance = feature_importance.sort_values()\n",
    "# Making threshold smaller\n",
    "thresh_num = X_validation.shape[1]\n",
    "\n",
    "feature_result = pd.DataFrame(columns=('Last_Feature', 'Thresh', 'Acc', 'Kapp', 'AUC', 'Recall', 'Precis'))\n",
    "low_thresh = feature_importance[0]\n",
    "print(feature_importance[0])\n",
    "for i in range(feature_importance.size-thresh_num, feature_importance.size-2):\n",
    "    # select features using threshold\n",
    "    if feature_importance[i] == low_thresh:\n",
    "        continue\n",
    "    else:\n",
    "        low_thresh = feature_importance[i]\n",
    "#         print(feature_importance[i])\n",
    "    selection = SelectFromModel(model, threshold=feature_importance[i], prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "\n",
    "    select_X_test = selection.transform(X_validation)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    #metric calculation\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_validation, predictions, pos_label=1)\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    cm = confusion_matrix(y_validation, predictions)\n",
    "#     print(confusion_matrix(y_validation, predictions))\n",
    "\n",
    "    kappa = cohen_kappa_score(y_validation, predictions)\n",
    "    acc = float(cm[0][0] + cm[1][1]) / len(y_validation)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    recall = tpr[1]\n",
    "    precis = float(cm[1][1]) / (cm[1][1] + cm[0][1])\n",
    "\n",
    "#     print(\"Thresh=%.3f, n=%d\" % (feature_importance[i], select_X_train.shape[1]))\n",
    "#     print('Accuracy = {0} \\n \\n'.format(acc))\n",
    "#     print('kappa score = {0} \\n \\n'.format(kappa))\n",
    "#     print('AUC Score = {0} \\n \\n'.format(auc))\n",
    "#     print('recall = {0} \\n \\n'.format(recall))\n",
    "#     print('precision = {0} \\n \\n'.format(precis))\n",
    "\n",
    "    feature_result.loc[i] = [feature_importance.index[i], feature_importance[i], acc, kappa, auc, recall, precis]\n",
    "\n",
    "#find the best f1\n",
    "feature_result['F1'] = 2* (feature_result['Recall']*feature_result['Precis']) / (feature_result['Recall']+feature_result['Precis'])\n",
    "max_f1 = feature_result['F1'].idxmax()\n",
    "best_row = feature_result.loc[feature_result['F1'].idxmax()]\n",
    "print(\"best row:\")\n",
    "print(best_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_result.to_csv(\"Feature_Selection_Results{0}.csv\".format(datetime.datetime.now().strftime('%m%d-%H%M%S')), 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Tuning for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=65, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Model setted up\n"
     ]
    }
   ],
   "source": [
    "thres = feature_result.loc[feature_result['F1'] == feature_result['F1'][max_f1]]\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "selection = SelectFromModel(model, threshold=thres.iloc[0]['Thresh'], prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "select_X_test = selection.transform(impute_X_test)\n",
    "\n",
    "scores=['f1']\n",
    "tscv =TimeSeriesSplit(n_splits=3) \n",
    "\n",
    "tuned_parameters= {'n_estimators':[1,10,100,1000,10000],\n",
    "                   'max_depth':[1,5,10,20,50,100],\n",
    "                   'max_features':['sqrt','log2']}\n",
    "print (\"## Tuning for %s\"%model)\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(model, tuned_parameters, cv=tscv,scoring= score)\n",
    "    print('Model setted up')\n",
    "    clf.fit(select_X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(select_X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best params before fixing the time bug\n",
    "0.770 (+/-0.032) for {'max_features': 'log2', 'max_depth': 5, 'n_estimators': 1000}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full development set.\n",
    "The scores are computed on the full evaluation set.\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.93      0.86      0.89       483\n",
    "        1.0       0.71      0.85      0.77       203\n",
    "\n",
    "avg / total       0.87      0.85      0.86       686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266 217]\n",
      " [118  85]]\n",
      "Final Test Data Results\n",
      "Thresh=0, n=14\n",
      "Accuracy = 0.5116618075801749 \n",
      " \n",
      "\n",
      "kappa score = -0.026771752048539543 \n",
      " \n",
      "\n",
      "AUC Score = 0.4847219247519098 \n",
      " \n",
      "\n",
      "recall = 0.4187192118226601 \n",
      " \n",
      "\n",
      "precision = 0.2814569536423841 \n",
      " \n",
      "\n",
      "ï..AGENCY_y                                                  0.095929\n",
      "amount                                                       0.027298\n",
      "321 - EMS call, excluding vehicle accident with injury       0.023977\n",
      "6111 - Dispatched & cancelled on arrival                     0.020011\n",
      "600 - Good intent call, Other                                0.019235\n",
      "SALEPRICE                                                    0.019089\n",
      "ï..AGENCY_x                                                  0.018960\n",
      "City & School Tax Lien                                       0.018080\n",
      "311 - Medical assist, assist EMS crew                        0.017048\n",
      "Allegheny County Tax Lien                                    0.016274\n",
      "743 - Smoke detector activation, no fire - unintentional     0.012279\n",
      "City of Pittsburgh Tax Lien                                  0.011952\n",
      "Estimate; Owner occupied: - Moved in 1979 or earlier         0.011419\n",
      "School District Tax Lien                                     0.011033\n",
      "300 - Rescue, EMS incident, other                            0.010178\n",
      "4441 - Cable/Telco Wires Down                                0.010027\n",
      "CONDOMINIUM                                                  0.009851\n",
      "611 - Dispatched & cancelled en route                        0.009778\n",
      "Estimate; Owner occupied: - Moved in 1990 to 1999            0.009564\n",
      "Estimate; Total: - Built 1939 or earlier                     0.009300\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#test on the test data\n",
    "tuned_model = RandomForestClassifier(n_estimators = 1000, max_depth=10, random_state=27,max_features='log2')\n",
    "tuned_model.fit(select_X_train, y_train)\n",
    "y_pred = tuned_model.predict(select_X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(impute_y_test, predictions, pos_label=1)\n",
    "accuracy = accuracy_score(impute_y_test, predictions)\n",
    "cm = confusion_matrix(impute_y_test, predictions)\n",
    "print(confusion_matrix(impute_y_test, predictions))\n",
    "\n",
    "kappa = cohen_kappa_score(impute_y_test, predictions)\n",
    "acc = float(cm[0][0] + cm[1][1]) / len(impute_y_test)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "recall = tpr[1]\n",
    "precis = float(cm[1][1]) / (cm[1][1] + cm[0][1])\n",
    "\n",
    "print('Final Test Data Results')\n",
    "print(\"Thresh=%d, n=%d\" % (thres.iloc[0]['Thresh'], select_X_test.shape[1]))\n",
    "print('Accuracy = {0} \\n \\n'.format(acc))\n",
    "print('kappa score = {0} \\n \\n'.format(kappa))\n",
    "print('AUC Score = {0} \\n \\n'.format(auc))\n",
    "print('recall = {0} \\n \\n'.format(recall))\n",
    "print('precision = {0} \\n \\n'.format(precis))\n",
    "\n",
    "\n",
    "#Tree model for getting features importance\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "UsedDf = encoded_traindata.drop('fire',axis=1)\n",
    "important_features = pd.Series(data=clf.feature_importances_,index=UsedDf.columns)\n",
    "important_features.sort_values(ascending=False,inplace=True)\n",
    "#top 20 features\n",
    "print(important_features[0:20])\n",
    "\n",
    "#Plotting the top 20 features\n",
    "y_pos = np.arange(len(important_features.index[0:20]))\n",
    "\n",
    "plt.bar(y_pos,important_features.values[0:20], alpha=0.3)\n",
    "plt.xticks(y_pos, important_features.index[0:20], rotation = (90), fontsize = 11, ha='left')\n",
    "plt.ylabel('Feature Importance Scores')\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "\n",
    "#features_png = \"{0}FeatureImportancePlot_{1}.png\".format(png_path, datetime.datetime.now())\n",
    "#plt.savefig(features_png, dpi=150)\n",
    "#plt.clf()\n",
    "# Write model performance to log file:\n",
    "log_path = os.path.join(curr_path, \"log/\")\n",
    "important_features[0:50].to_csv('{0}FeatureImportanceList_{1}.csv'.format(log_path, datetime.datetime.now().strftime('%m%d-%H%M%S')), 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:crookshanks]",
   "language": "python",
   "name": "conda-env-crookshanks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
